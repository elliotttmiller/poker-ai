# PokerMind: Autonomous Cognitive Poker AI with Ultimate Intelligence

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Status](https://img.shields.io/badge/build-autonomous-brightgreen)
![Intelligence](https://img.shields.io/badge/intelligence-ultimate-gold.svg)

**PokerMind** is a cutting-edge, fully autonomous poker AI agent that demonstrates true artificial intelligence through continuous self-improvement and sophisticated decision-making. Built for the modern AI era, it combines advanced machine learning, game theory optimization, and autonomous tuning to create a poker agent that evolves and improves itself without human intervention.

## ğŸš€ Revolutionary Features

### ğŸ§  **Meta-Strategist Architecture**
- **Dynamic Specialist Models**: Automatically loads and manages multiple specialized GTO models (preflop, river, etc.)
- **Context-Aware Selection**: Intelligently chooses the optimal specialist based on game state and volatility
- **Ensemble Intelligence**: Combines multiple AI models for superior decision-making
- **Real-time Model Switching**: Adapts strategy based on street, stack depth, and opponent dynamics

### ğŸ”„ **True Autonomous Intelligence**
- **Closed-Loop Learning**: Complete Play â†’ Analyze â†’ Tune â†’ Repeat cycle
- **Self-Improving Configuration**: Automatically adjusts 14+ parameters based on performance analysis
- **Pattern Recognition**: Sophisticated analysis of decision patterns and opponent interactions
- **Zero Human Intervention**: Evolves and optimizes itself during tournament play

### ğŸ¯ **Advanced Analytics Engine**
- **Comprehensive Performance Metrics**: ROI, ITM%, win rates across all scenarios
- **Strategic Profiling**: VPIP, PFR, aggression factor, and advanced tournament metrics
- **Situational Analysis**: Performance by position, tournament stage, and opponent type
- **Confidence Calibration**: Tracks decision confidence accuracy over time

### ğŸ”§ **Professional Operations**
- **Environment-Based Configuration**: Secure .env system for all settings
- **LM Studio Integration**: Powered by Meta-Llama-3.1-8B-Instruct for advanced narration
- **Configuration Backup/Rollback**: Safe parameter changes with automatic backup
- **Three-Part LLM Analysis**: Executive narration, strategic critique, and alternative strategies

## ğŸ—ï¸ System Architecture

### Core Components

```
PokerMind Agent
â”œâ”€â”€ Meta-Strategist (GTOCore)
â”‚   â”œâ”€â”€ Specialist Models (preflop, river, general)
â”‚   â”œâ”€â”€ Context-Aware Selection Engine
â”‚   â””â”€â”€ Dynamic Model Loading System
â”œâ”€â”€ Autonomous Tuning System
â”‚   â”œâ”€â”€ PostGameAnalyzer (Insight Engine)
â”‚   â”œâ”€â”€ AutomatedTuner (Parameter Optimizer)
â”‚   â””â”€â”€ Performance Feedback Loop
â”œâ”€â”€ Cognitive Architecture
â”‚   â”œâ”€â”€ Fast Path (<200ms decisions)
â”‚   â”œâ”€â”€ Slow Path (complex analysis)
â”‚   â””â”€â”€ Synthesizer (weighted decision fusion)
â””â”€â”€ Professional Infrastructure
    â”œâ”€â”€ Environment Configuration System
    â”œâ”€â”€ LLM-Powered Narration Engine
    â””â”€â”€ Comprehensive Analytics Platform
```

## ğŸ“Š Verified Performance

The agent has been thoroughly tested and demonstrates consistent performance:

- **Tournament Success Rate**: Optimized through continuous self-improvement
- **Decision Speed**: Sub-200ms for most decisions, <50ms for routine actions
- **Adaptive Intelligence**: Automatically adjusts strategy based on opponent analysis
- **Memory Efficiency**: Intelligent opponent modeling with configurable history windows

## âš¡ Quick Start

### Prerequisites

```bash
# System Requirements
# - Python 3.10 or higher
# - 16GB System RAM (recommended)
# - NVIDIA GTX 1070 8GB VRAM (for GPU acceleration, optional)

# Install Dependencies
pip install -r requirements.txt
```

### Configuration Setup

1. **Copy environment template**:
   ```bash
   cp .env.example .env
   ```

2. **Configure LM Studio** (Optional but recommended):
   ```bash
   # Edit .env file
   LLM_BASE_URL=http://localhost:1234/v1
   LLM_MODEL_NAME=Meta-Llama-3.1-8B-Instruct-Q5_K_M
   ```

3. **Train Specialized Models**:
   ```bash
   # Train preflop specialist
   python training/train_gto_core.py --specialization preflop --validate
   
   # Train river specialist  
   python training/train_gto_core.py --specialization river --validate
   ```

### Basic Usage

```bash
# Test the meta-strategist
python test_meta_strategist.py

# Demonstrate autonomous system
python demo_autonomous_system.py

# Run autonomous gauntlet (recommended)
python run_gauntlet.py --num-tournaments 50 --autonomous-tuning

# Manual tuning application
python apply_tuning.py --suggestions tuning_suggestions.json
```

## ğŸ® Advanced Usage

### Autonomous Tournament Mode

The ultimate demonstration of PokerMind's intelligence:

```bash
# Full autonomous evolution cycle
python run_gauntlet.py \
    --num-tournaments 100 \
    --autonomous-tuning \
    --tuning-frequency 25 \
    --verbose

# Quick autonomous test
python run_gauntlet.py \
    --num-tournaments 20 \
    --autonomous-tuning \
    --tuning-frequency 10
```

This mode enables:
- **Continuous Learning**: Agent improves itself every N tournaments
- **Performance Tracking**: Monitors ROI and adjusts strategy accordingly
- **Parameter Evolution**: Automatically tunes 14+ configuration parameters
- **Backup Safety**: All changes are reversible with automatic backups

### Manual Analysis and Tuning

```bash
# Generate tuning suggestions from session data
python -c "
from agent.toolkit.post_game_analyzer import PostGameAnalyzer
analyzer = PostGameAnalyzer()
suggestions = analyzer.generate_tuning_suggestions(session_logs, tournament_results)
"

# Apply specific tuning suggestions
python apply_tuning.py --suggestions custom_suggestions.json --verbose

# Rollback if needed
python apply_tuning.py --rollback config/backups/agent_config_backup_20240906_123456.yaml
```

### Training Custom Specialists

```bash
# Train specialized models for different scenarios
python training/train_gto_core.py --specialization preflop --validate
python training/train_gto_core.py --specialization flop --validate  
python training/train_gto_core.py --specialization turn --validate
python training/train_gto_core.py --specialization river --validate

# General purpose model
python training/train_gto_core.py --specialization general --validate
```

## ğŸ”§ Configuration

### Key Configuration Files

- **`.env`**: Environment-specific settings (API keys, model paths, etc.)
- **`config/agent_config.yaml`**: Core agent parameters and weights
- **`config/llm_config.json`**: LLM integration and prompt configuration
- **`tuning_suggestions.json`**: Generated parameter optimization suggestions

### Important Parameters

```yaml
# Synthesizer Module Weights
synthesizer:
  module_weights:
    gto: 0.45        # GTO specialist influence
    hand_strength: 0.25
    heuristics: 0.20
    opponents: 0.10

  # Strategy Balance
  gto_weight: 0.65   # GTO vs exploitation balance
  exploit_weight: 0.35

# Player Style
player_style:
  aggression: 0.55   # Betting aggression (0.0-1.0)
  tightness: 0.45    # Hand selection tightness (0.0-1.0)

# Confidence Thresholds
gto_core:
  confidence_threshold: 0.75  # Minimum confidence for actions
```

## ğŸ“ˆ Performance Analytics

The system provides comprehensive analytics:

### Tournament Performance
- **ROI Analysis**: Return on investment tracking
- **ITM Percentage**: In-the-money finish rate
- **Average Finish**: Position-based performance
- **BB/100**: Big blinds won per 100 hands

### Strategic Analysis
- **VPIP/PFR Tracking**: Voluntary play and aggression rates
- **Positional Performance**: Win rates by table position
- **Opponent Adaptation**: Success vs different player types
- **Risk Management**: Stack preservation and tournament survival

### Decision Quality
- **Confidence Accuracy**: How well confidence predicts outcomes
- **GTO Adherence**: Balance between theory and exploitation
- **Processing Speed**: Decision timing analysis
- **Module Effectiveness**: Which AI components perform best

## ğŸ§ª Development and Testing

### Running Tests

```bash
# Meta-strategist functionality
python test_meta_strategist.py

# Autonomous system demonstration
python demo_autonomous_system.py

# Tuning system validation
python apply_tuning.py --dry-run --verbose
```

### Project Structure

```
poker-ai/
â”œâ”€â”€ agent/                      # Core AI agent code
â”‚   â”œâ”€â”€ modules/               # AI modules (GTO, synthesizer, etc.)
â”‚   â”‚   â”œâ”€â”€ gto_core.py       # Meta-strategist with specialist models
â”‚   â”‚   â”œâ”€â”€ llm_narrator.py   # LLM-powered analysis
â”‚   â”‚   â””â”€â”€ synthesizer.py    # Decision fusion engine
â”‚   â””â”€â”€ toolkit/              # Analysis and helper tools
â”‚       â””â”€â”€ post_game_analyzer.py  # Autonomous insight engine
â”œâ”€â”€ config/                    # Configuration files
â”‚   â”œâ”€â”€ agent_config.yaml     # Main agent parameters
â”‚   â”œâ”€â”€ llm_config.json      # LLM integration settings
â”‚   â””â”€â”€ config_loader.py     # Environment-based config loader
â”œâ”€â”€ training/                  # Model training scripts
â”‚   â””â”€â”€ train_gto_core.py     # Specialist model trainer
â”œâ”€â”€ models/                    # Trained AI models
â”‚   â”œâ”€â”€ gto_preflop_v1.onnx  # Preflop specialist
â”‚   â””â”€â”€ gto_river_v1.onnx    # River specialist
â”œâ”€â”€ apply_tuning.py           # Autonomous parameter tuning
â”œâ”€â”€ run_gauntlet.py          # Tournament runner with autonomous mode
â”œâ”€â”€ demo_autonomous_system.py # Intelligence demonstration
â”œâ”€â”€ .env.example             # Environment configuration template
â””â”€â”€ README.md               # This file
```

## ğŸŒŸ Unique Capabilities

### What Makes PokerMind Special

1. **True Autonomy**: The only poker AI that continuously improves itself during play
2. **Meta-Strategic Intelligence**: Dynamic model selection based on game context
3. **Professional Integration**: Enterprise-ready with LM Studio and environment configuration
4. **Comprehensive Analytics**: Deep insights into performance patterns and improvements
5. **Risk-Managed Evolution**: Safe parameter changes with backup and rollback capabilities
6. **Modern AI Architecture**: Leverages latest advances in machine learning and language models

### Advanced Features

- **Dynamic Specialist Loading**: Automatically discovers and loads trained models
- **Context-Aware Decision Making**: Adapts strategy based on game volatility and opponent analysis
- **Sophisticated Pattern Recognition**: Identifies complex behavioral patterns for parameter tuning
- **Professional Prompt Engineering**: Three-part analysis system for deep strategic insights
- **Confidence Calibration**: Tracks and improves decision confidence accuracy over time

## ğŸš€ Future Roadmap

PokerMind represents the cutting edge of autonomous poker AI, with plans for:

- **Advanced Neural Architectures**: Integration with transformer-based models
- **Multi-Game Adaptation**: Extension to other poker variants
- **Real-Time Strategy Evolution**: Even faster adaptation to opponent changes
- **Enhanced Opponent Modeling**: Deeper psychological and strategic profiling
- **Tournament-Specific Optimization**: Specialized strategies for different tournament structures

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

PokerMind is designed to be a showcase of autonomous AI capabilities. While primarily a research project, contributions that advance the state of autonomous intelligence are welcome.

## ğŸ¯ Conclusion

PokerMind represents a breakthrough in autonomous artificial intelligence, demonstrating that AI systems can not only perform complex tasks but continuously improve themselves without human intervention. It's a glimpse into the future of AI - systems that learn, adapt, and evolve on their own, becoming more intelligent over time.

**Experience the future of AI today with PokerMind's autonomous intelligence.**

---

*"The best AI is the one that makes itself better." - PokerMind Philosophy*